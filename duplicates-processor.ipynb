{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import string\n",
    "from collections import Counter, defaultdict\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import os\n",
    "import itertools as it\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group images by size to increase computationally efficiency:\n",
    "\n",
    "def Image_Optimizer(name_size):\n",
    "\n",
    "    short_list = []\n",
    "    files_investigate = {}\n",
    "    counts = dict()\n",
    "\n",
    "    # find unique image size values & store in a dictionary:\n",
    "\n",
    "    size_list = [n[1] for m,n in enumerate(name_size)]  \n",
    "\n",
    "    poss_dupes = set(size_list)     \n",
    "\n",
    "    for m, n in enumerate(name_size):\n",
    "        if n[1] in poss_dupes:           \n",
    "            counts[n[1]] = counts.get(n[1], 0) + 1\n",
    "\n",
    "    # remove items with values = 1 to use as a checksum:\n",
    "\n",
    "    short_list = [c for c in counts if counts[c] > 1]  \n",
    "\n",
    "    # create a dictionary where keys = file size and values = lists of file names.\n",
    "\n",
    "\n",
    "    for ns in name_size:\n",
    "        if ns[1] in files_investigate:\n",
    "             files_investigate[ns[1]].append(ns[0])\n",
    "        else:\n",
    "            files_investigate[ns[1]] = [ns[0]]\n",
    "\n",
    "    # dictionary filters `files_investigate` for values > 1:\n",
    "\n",
    "    filtered_dict = defaultdict(list)\n",
    "\n",
    "    for k, v in files_investigate.items():\n",
    "        if len(v) > 1:\n",
    "            filtered_dict[k].append(v)\n",
    "\n",
    "    if len(short_list) == len(filtered_dict):\n",
    "        print('>> Created {} groups of images to compare\\n'.format(len(short_list)))\n",
    "        return(filtered_dict)\n",
    "    else:\n",
    "        print(\"Error detected.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for redundant images in <path> directory:\n",
    "\n",
    "def Check_Duplicates(path):\n",
    "    \n",
    "    duplicates_list, corrupted_list, size_list, name_size = [], [], [], []\n",
    "    comp_dict = {}\n",
    "\n",
    "    # create list of all files in directory & check for errors:\n",
    "    \n",
    "    img_list = [i for i in os.listdir(path)] \n",
    "    \n",
    "    for i, j in enumerate(img_list):\n",
    "        read = cv2.imread(path + j)\n",
    "    \n",
    "        # create list of tuples in filename, size format:\n",
    "\n",
    "        try:\n",
    "            temp = read.shape\n",
    "            size_list = (j, temp)\n",
    "            name_size.append(size_list)\n",
    "\n",
    "        except:\n",
    "            if j == '.ipynb_checkpoints':\n",
    "                shutil.rmtree(path + j)     # remove jupyter labs checkpoint file if present\n",
    "            else:\n",
    "                print('Bad image found:', j)\n",
    "    \n",
    "    print('Original image list size:', len(name_size))\n",
    "    \n",
    "    # optimize processing by organizing images into groups of equal size:\n",
    "    \n",
    "    prepped_images = Image_Optimizer(name_size)   \n",
    "    \n",
    "    # conduct pairwise comparison of images sharing a key:\n",
    "    \n",
    "    for k, v in prepped_images.items():\n",
    "        v = sum(v, [])                        # flatten values list\n",
    "        img_combos = it.combinations(v, 2)    # create list of pairwise combinations from values\n",
    "\n",
    "        print('Image combinations being processed:', len(list(img_combos)))\n",
    "\n",
    "        for i, j in enumerate(img_combos):\n",
    "            try:\n",
    "                original = cv2.imread(path + j[0])\n",
    "                duplicate = cv2.imread(path + j[1])\n",
    "\n",
    "                if original.shape == duplicate.shape:    # double check that image dimensions equal \n",
    "                  \n",
    "                # compute image differences and split by channel:\n",
    "                \n",
    "                    difference = cv2.subtract(original, duplicate)\n",
    "                    b, g, r = cv2.split(difference)\n",
    "\n",
    "                    if cv2.countNonZero(b) == 0 and cv2.countNonZero(g) == 0 and cv2.countNonZero(r) == 0:\n",
    "                        print('Images are completely Equal:', j)\n",
    "                        duplicates_list.append(j)    # append duplicate filenames to list\n",
    "            \n",
    "            except:\n",
    "                print('Bad file(s) detected:', fname)\n",
    "                corrupted_list.append(fname)\n",
    "                \n",
    "    print('Duplicates: ', len(duplicates_list))\n",
    "    print('Corrupted: ', len(corrupted_list))\n",
    "    \n",
    "    if len(duplicates_list) > 0:\n",
    "        \n",
    "        d_list = [i[0] for i in duplicates_list]\n",
    "        \n",
    "        for dl in duplicates_list:\n",
    "            if dl[0] in comp_dict:\n",
    "                comp_dict[dl[0]].append(dl[1])\n",
    "            else:\n",
    "                comp_dict[dl[0]] = [dl[1]]\n",
    "        \n",
    "        # compile a list of values from comp_dict to delete:\n",
    "        \n",
    "        dump_list = []\n",
    "        \n",
    "        for cd, v in comp_dict.items():\n",
    "            dump_list.extend(v)\n",
    "        \n",
    "        print('Dump List:',len(dump_list))\n",
    "        \n",
    "        # remove duplicate values and convert to ordered data structure\n",
    "        \n",
    "        dump_list = list(set(dump_list))    \n",
    "        print(dump_list)\n",
    "        \n",
    "        # user confirmation to delete files:\n",
    "        \n",
    "        user_answer = input('Remove duplicate files? [y] or [n]')\n",
    "\n",
    "        if user_answer == 'y':\n",
    "            ctr = 0\n",
    "            for d in dump_list:\n",
    "                os.remove(path + d)\n",
    "                ctr += 1\n",
    "            print('Deleted {} files.'.format(ctr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run duplicates function:\n",
    "\n",
    "Check_Duplicates(path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
